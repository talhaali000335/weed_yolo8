<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>AgriVision AI ‚Ä¢ Live Weed & Crop Detection (ONNX Runtime Web)</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.19.2/dist/ort.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Inter', sans-serif; background: #000; color: #fff; overflow: hidden; height: 100vh; }
        .container { position: relative; width: 100%; height: 100%; background: #000; }

        video { width: 100%; height: 100%; object-fit: cover; }

        canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none; }

        .status-bar {
            position: absolute; top: 20px; left: 50%; transform: translateX(-50%);
            background: rgba(0,0,0,0.7); backdrop-filter: blur(16px);
            padding: 12px 24px; border-radius: 30px; z-index: 100;
            border: 1px solid rgba(255,255,255,0.1); box-shadow: 0 8px 32px rgba(0,0,0,0.5);
            font-weight: 600; font-size: 14px;
        }
        .dot { width: 10px; height: 10px; border-radius: 50%; background: #00ff88; display: inline-block; margin-right: 10px; box-shadow: 0 0 20px #00ff88; }

        .bottom-panel {
            position: absolute; bottom: 0; left: 0; right: 0; z-index: 50;
            background: rgba(10,10,15,0.95); backdrop-filter: blur(20px);
            border-top: 1px solid rgba(255,255,255,0.1);
            border-radius: 24px 24px 0 0;
            padding: 20px; transition: transform 0.4s cubic-bezier(0.32,1,0.32,1);
            transform: translateY(0);
        }
        .drag-handle {
            width: 50px; height: 5px; background: rgba(255,255,255,0.3); border-radius: 3px;
            margin: 0 auto 16px; cursor: grab;
        }

        .stats {
            display: grid; grid-template-columns: repeat(3, 1fr); gap: 16px; text-align: center;
        }
        .stat {
            background: rgba(255,255,255,0.05); padding: 16px; border-radius: 16px;
            border: 1px solid rgba(255,255,255,0.08);
        }
        .stat-icon { font-size: 32px; margin-bottom: 8px; }
        .stat-count { font-size: 36px; font-weight: 700; margin: 8px 0; }
        .stat-label { font-size: 13px; opacity: 0.8; }

        .controls {
            display: flex; justify-content: center; gap: 16px; margin-top: 20px;
        }
        button {
            padding: 14px 28px; font-size: 1.1rem; border: none;
            border-radius: 30px; cursor: pointer; transition: all 0.3s;
        }
        #reset-btn { background: #ff4444; color: white; }
        #reset-btn:hover { background: #ff3333; }

        .confidence {
            margin-top: 16px; text-align: center;
        }
        .confidence-bar {
            height: 8px; background: rgba(255,255,255,0.1); border-radius: 4px; overflow: hidden;
        }
        .fill { height: 100%; background: linear-gradient(90deg, #00ff88, #00cc66); transition: width 0.5s ease; }
    </style>
</head>
<body>
    <div class="container">
        <video id="video" autoplay playsinline muted></video>
        <canvas id="canvas"></canvas>

        <div class="status-bar">
            <span class="dot"></span>
            <span id="status-text">Loading model...</span>
        </div>

        <div class="bottom-panel" id="bottom-panel">
            <div class="drag-handle"></div>

            <div class="stats">
                <div class="stat">
                    <div class="stat-icon">üåø</div>
                    <div class="stat-count" id="crop-count">0</div>
                    <div class="stat-label">Crops</div>
                </div>
                <div class="stat">
                    <div class="stat-icon">‚ö†Ô∏è</div>
                    <div class="stat-count" id="weed-count">0</div>
                    <div class="stat-label">Weeds</div>
                </div>
                <div class="stat">
                    <div class="stat-icon">üìä</div>
                    <div class="stat-count" id="total-count">0</div>
                    <div class="stat-label">Total</div>
                </div>
            </div>

            <div class="confidence">
                <div class="confidence-bar"><div class="fill" id="conf-fill" style="width:0%"></div></div>
                <div style="margin-top:8px; opacity:0.8;">Avg Confidence: <span id="conf-text">0%</span></div>
            </div>

            <div class="controls">
                <button id="reset-btn">Reset Counts</button>
            </div>
        </div>
    </div>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const statusText = document.getElementById('status-text');
        const cropCount = document.getElementById('crop-count');
        const weedCount = document.getElementById('weed-count');
        const totalCount = document.getElementById('total-count');
        const confFill = document.getElementById('conf-fill');
        const confText = document.getElementById('conf-text');
        const resetBtn = document.getElementById('reset-btn');

        let session;
        let isRunning = true;
        let frameCount = 0;

        // Tracking
        let nextId = 1;
        const trackers = new Map(); // id ‚Üí {bbox, class, label, age, totalVisibleCount}

        // Load model
        async function loadModel() {
            try {
                statusText.textContent = "Loading YOLOv11 model...";
                const session = await ort.InferenceSession.create('best_web_model/model.onnx');
                statusText.textContent = "Model loaded ‚Äì detecting live!";
                console.log("ONNX model loaded");
                startDetection();
            } catch (e) {
                statusText.textContent = "Failed to load model";
                console.error(e);
            }
        }

        // Webcam
        async function startCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'environment', width: { ideal: 1280 }, height: { ideal: 720 } }
            });
            video.srcObject = stream;
            video.onloadedmetadata = () => {
                video.play();
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
            };
        }

        // Simple IOU for tracking
        function iou(box1, box2) {
            const [x1, y1, x2, y2] = box1;
            const [xA, yA, xB, yB] = box2;
            const xi1 = Math.max(x1, xA);
            const yi1 = Math.max(y1, yA);
            const xi2 = Math.min(x2, xB);
            const yi2 = Math.min(y2, yB);
            const interArea = Math.max(0, xi2 - xi1) * Math.max(0, yi2 - yi1);
            const box1Area = (x2 - x1) * (y2 - y1);
            const box2Area = (xB - xA) * (yB - yA);
            return interArea / (box1Area + box2Area - interArea);
        }

        // Main detection loop
        async function startDetection() {
            if (!isRunning) return;

            frameCount++;
            tf.engine().startScope();

            const img = tf.browser.fromPixels(video);
            const resized = tf.image.resizeBilinear(img, [640, 640]);
            const normalized = resized.div(255.0);
            const input = normalized.expandDims(0);

            // ONNX Runtime Web inference
            try {
                const feeds = { images: input };
                const results = await session.run(feeds);
                const output = results.output_0; // assuming output named "output_0" in ONNX

                // Shape: [1, 8400, 6] for 2 classes
                const data = await output.data();
                const numBoxes = 8400;

                const detections = [];
                const threshold = 0.4;

                for (let i = 0; i < numBoxes; i++) {
                    const offset = i * 6;
                    const cx = data[offset];
                    const cy = data[offset + 1];
                    const w = data[offset + 2];
                    const h = data[offset + 3];
                    const weedConf = data[offset + 4];
                    const cropConf = data[offset + 5];

                    const conf = Math.max(weedConf, cropConf);
                    if (conf < threshold) continue;

                    const classId = weedConf > cropConf ? 0 : 1;
                    const x = (cx - w / 2) * 640;
                    const y = (cy - h / 2) * 640;
                    const width = w * 640;
                    const height = h * 640;

                    detections.push({
                        bbox: [x, y, x + width, y + height],
                        confidence: conf,
                        classId
                    });
                }

                // Simple SORT-like tracking
                const matched = new Set();
                const newTrackers = new Map();

                detections.forEach(det => {
                    let bestMatch = null;
                    let bestIou = 0;

                    trackers.forEach((tracker, id) => {
                        const i = iou(det.bbox, tracker.bbox);
                        if (i > bestIou && i > 0.3) {
                            bestIou = i;
                            bestMatch = id;
                        }
                    });

                    if (bestMatch !== null) {
                        matched.add(bestMatch);
                        const t = trackers.get(bestMatch);
                        t.bbox = det.bbox;
                        t.confidence = det.confidence;
                        t.age = 0;
                        t.totalVisibleCount++;
                        newTrackers.set(bestMatch, t);
                    } else {
                        const id = nextId++;
                        const label = det.classId === 0 ? `WEED #${id}` : `CROP #${id}`;
                        newTrackers.set(id, {
                            bbox: det.bbox,
                            classId: det.classId,
                            label,
                            confidence: det.confidence,
                            age: 0,
                            totalVisibleCount: 1
                        });
                    }
                });

                trackers.forEach((t, id) => {
                    if (!matched.has(id)) {
                        t.age++;
                        if (t.age < 30) newTrackers.set(id, t);
                    }
                });

                trackers.clear();
                newTrackers.forEach((t, id) => trackers.set(id, t));

                // Draw
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                let visibleWeeds = 0;
                let visibleCrops = 0;
                let sumConf = 0;

                trackers.forEach(t => {
                    if (t.age > 0) return; // only draw visible

                    const [x1, y1, x2, y2] = t.bbox;
                    const scaleX = canvas.width / 640;
                    const scaleY = canvas.height / 640;

                    const sx1 = x1 * scaleX;
                    const sy1 = y1 * scaleY;
                    const sx2 = x2 * scaleX;
                    const sy2 = y2 * scaleY;

                    const isWeed = t.classId === 0;
                    const color = isWeed ? '#ff4444' : '#44ff44';

                    ctx.strokeStyle = color;
                    ctx.lineWidth = 4;
                    ctx.strokeRect(sx1, sy1, sx2 - sx1, sy2 - sy1);

                    const label = `${t.label} ${(t.confidence * 100).toFixed(0)}%`;
                    const textWidth = ctx.measureText(label).width;

                    ctx.fillStyle = color;
                    ctx.fillRect(sx1, sy1 - 34, textWidth + 20, 34);

                    ctx.fillStyle = 'white';
                    ctx.font = 'bold 16px Inter';
                    ctx.fillText(label, sx1 + 10, sy1 - 10);

                    if (isWeed) visibleWeeds++;
                    else visibleCrops++;
                    sumConf += t.confidence;
                });

                // Update UI
                weedCount.textContent = visibleWeeds;
                cropCount.textContent = visibleCrops;
                totalCount.textContent = visibleWeeds + visibleCrops;
                const avg = visibleWeeds + visibleCrops > 0 ? sumConf / (visibleWeeds + visibleCrops) : 0;
                confFill.style.width = `${avg * 100}%`;
                confText.textContent = `${(avg * 100).toFixed(1)}%`;

                tf.engine().endScope();
                requestAnimationFrame(startDetection);
            } catch (e) {
                console.error("Detection error:", e);
                statusText.textContent = "Detection error";
                requestAnimationFrame(startDetection);
            }
        }

        // Reset
        resetBtn.onclick = () => {
            nextId = 1;
            trackers.clear();
            statusText.textContent = "Counts reset";
        };

        startCamera();
        loadModel();
    </script>
</body>
</html>
